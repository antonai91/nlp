{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_bert_classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPYWnYUbWkfvaOnSQYqQUM+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTUBOLfW0YxO","executionInfo":{"status":"ok","timestamp":1616869074736,"user_tz":-60,"elapsed":470,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"cb35272d-2a60-4961-f13f-b7be9e65e3f4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bs67a9A0ZeO","executionInfo":{"status":"ok","timestamp":1616869074936,"user_tz":-60,"elapsed":658,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"7bf2140e-c865-40f1-de79-c18dddf53f9a"},"source":["%cd gdrive/MyDrive/colab_projects/nlp/imdb/nbs/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/colab_projects/nlp/imdb/nbs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jbgLmMW10SNC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616869077461,"user_tz":-60,"elapsed":3175,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"335aa8bc-016f-4a0a-91f2-4c736416850e"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZflMy3Q0adw","executionInfo":{"status":"ok","timestamp":1616869078849,"user_tz":-60,"elapsed":4556,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","import tensorflow as tf\n","from transformers import BertTokenizer, TFBertForSequenceClassification, BertConfig\n","\n","# Load Huggingface transformers\n","from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n","# Then what you need from tensorflow.keras\n","from tensorflow.keras.layers import Input, Dropout, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.initializers import TruncatedNormal\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy\n","from tensorflow.keras.utils import to_categorical\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRwCGK1KGuMX","executionInfo":{"status":"ok","timestamp":1616869078852,"user_tz":-60,"elapsed":4554,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["pd.options.display.max_columns=999\n","pd.options.display.max_rows=999"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldEnpePBajiX","executionInfo":{"status":"ok","timestamp":1616869079167,"user_tz":-60,"elapsed":4863,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["df = pd.read_csv(\"../data/imdb.csv\")\n","df_train = df[:25000]\n","df_test = df[25000:]\n","\n","labels_index = {'positive':1, 'negative':0}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJM4v_HEahxO","executionInfo":{"status":"ok","timestamp":1616869082922,"user_tz":-60,"elapsed":8612,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"ccef7f33-2f7d-42ab-b5b0-3f6fb5f94a80"},"source":["# Name of the BERT model to use\n","model_name = 'bert-base-uncased'\n","# Max length of tokens\n","max_length = 1000\n","# Load transformers config and set output_hidden_states to False\n","config = BertConfig.from_pretrained(model_name)\n","config.output_hidden_states = False\n","# Load BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n","# Load the Transformers BERT model\n","transformer_model = TFBertModel.from_pretrained(model_name, config = config)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaOKT-ghbP0j","executionInfo":{"status":"ok","timestamp":1616869082923,"user_tz":-60,"elapsed":8606,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"a6613654-a154-491a-ebf5-76cc399f7d89"},"source":["transformer_model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  109482240 \n","=================================================================\n","Total params: 109,482,240\n","Trainable params: 109,482,240\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q3P1KNfAbTGO","executionInfo":{"status":"ok","timestamp":1616869082923,"user_tz":-60,"elapsed":8600,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["# Load the MainLayer\n","bert = transformer_model.layers[0]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ovq8G5bbeqd","executionInfo":{"status":"ok","timestamp":1616869082924,"user_tz":-60,"elapsed":8596,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n","from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n","from keras.models import Model"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nF48Ou8nbUJu","executionInfo":{"status":"ok","timestamp":1616869086554,"user_tz":-60,"elapsed":12219,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"71c98175-34a9-45e5-8d5a-c9ac0841d84f"},"source":["# Build your model input\n","input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n","inputs = {'input_ids': input_ids}\n","bert_model = bert(inputs)[1]\n","dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n","pooled_output = dropout(bert_model, training=False)\n","dense_inter = Dense(128, activation='relu')(pooled_output)\n","logits = Dense(2)(dense_inter)\n","model = Model(inputs=inputs, outputs=logits)\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_ids (InputLayer)       [(None, 1000)]            0         \n","_________________________________________________________________\n","bert (TFBertMainLayer)       TFBaseModelOutputWithPool 109482240 \n","_________________________________________________________________\n","pooled_output (Dropout)      (None, 768)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               98432     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 109,580,930\n","Trainable params: 109,580,930\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2N_JSo6Fb_wf","executionInfo":{"status":"ok","timestamp":1616869086555,"user_tz":-60,"elapsed":12214,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["# Set an optimizer\n","optimizer = Adam(\n","    learning_rate=1e-05,\n","    epsilon=1e-08,\n","    decay=0.01,\n","    clipnorm=1.0)\n","# Set loss and metrics\n","loss = CategoricalCrossentropy(from_logits=True)\n","metric = 'accuracy'\n","# Compile the model\n","model.compile(\n","    optimizer = optimizer,\n","    loss = loss, \n","    metrics = metric)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPxKmxrpahz1","executionInfo":{"status":"ok","timestamp":1616869086556,"user_tz":-60,"elapsed":12210,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["y_train = to_categorical(df_train['sentiment'].map(labels_index))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnDdKW4Sah27","executionInfo":{"status":"ok","timestamp":1616869086556,"user_tz":-60,"elapsed":12204,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["y_test = to_categorical(df_test['sentiment'].map(labels_index))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhSqtO2eah5b","executionInfo":{"status":"ok","timestamp":1616869095878,"user_tz":-60,"elapsed":21520,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["# Tokenize the input (takes some time)\n","X_train = tokenizer(\n","    text=df_train['review'].to_list(),\n","    add_special_tokens=True,\n","    max_length=max_length,\n","    truncation=True,\n","    padding=True, \n","    return_tensors='tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = False,\n","    verbose = True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePdCMtxfah8R","executionInfo":{"status":"ok","timestamp":1616869104811,"user_tz":-60,"elapsed":30447,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":["# Tokenize the input (takes some time)\n","X_test = tokenizer(\n","    text=df_test['review'].to_list(),\n","    add_special_tokens=True,\n","    max_length=max_length,\n","    truncation=True,\n","    padding=True, \n","    return_tensors='tf',\n","    return_token_type_ids = False,\n","    return_attention_mask = False,\n","    verbose = True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zO9mdtZOdCYr","executionInfo":{"status":"ok","timestamp":1616869104814,"user_tz":-60,"elapsed":30444,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"0fd9355d-33f5-4829-a63a-fceeb2918835"},"source":["X_train"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': <tf.Tensor: shape=(25000, 1000), dtype=int32, numpy=\n","array([[  101,  2028,  1997, ...,     0,     0,     0],\n","       [  101,  1037,  6919, ...,     0,     0,     0],\n","       [  101,  1045,  2245, ...,     0,     0,     0],\n","       ...,\n","       [  101, 10225, 25318, ...,     0,     0,     0],\n","       [  101,  9779,  2232, ...,     0,     0,     0],\n","       [  101,  2023,  2143, ...,     0,     0,     0]], dtype=int32)>}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEe6vIS_dMQu","executionInfo":{"status":"ok","timestamp":1616869104814,"user_tz":-60,"elapsed":30437,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"9764ff1f-efe6-4a74-81f4-1c697db3071a"},"source":["y_train"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1.],\n","       [0., 1.],\n","       [0., 1.],\n","       ...,\n","       [0., 1.],\n","       [0., 1.],\n","       [1., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PhrjfVKah_E","executionInfo":{"status":"ok","timestamp":1616877251556,"user_tz":-60,"elapsed":8177172,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"76197a40-ad89-48e9-a90b-a1facea4725f"},"source":["model.fit(X_train[\"input_ids\"], y_train, batch_size=4, epochs=2)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","6250/6250 [==============================] - 4081s 651ms/step - loss: 0.4470 - accuracy: 0.7733\n","Epoch 2/2\n","6250/6250 [==============================] - 4066s 651ms/step - loss: 0.2789 - accuracy: 0.9075\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4a2ad76710>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"31vOPHW1iM3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616877251558,"user_tz":-60,"elapsed":8177167,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"07d31d5b-2efa-468c-b1d2-04a4eb16edf9"},"source":["model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_ids (InputLayer)       [(None, 1000)]            0         \n","_________________________________________________________________\n","bert (TFBertMainLayer)       TFBaseModelOutputWithPool 109482240 \n","_________________________________________________________________\n","pooled_output (Dropout)      (None, 768)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               98432     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 109,580,930\n","Trainable params: 109,580,930\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eu-fNzC6kahp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616878423046,"user_tz":-60,"elapsed":9348650,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}},"outputId":"b6b6212a-ebbe-4698-e9cd-805f266d5d7d"},"source":["score, acc = model.evaluate(X_test[\"input_ids\"], y_test)\n","print('Test accuracy:', acc)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 1171s 1s/step - loss: 0.2602 - accuracy: 0.9106\n","Test accuracy: 0.9105600118637085\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4D6TXkmGHuxs","executionInfo":{"status":"ok","timestamp":1616878423048,"user_tz":-60,"elapsed":9348647,"user":{"displayName":"Antonio Lisi","photoUrl":"","userId":"11235078078976363784"}}},"source":[""],"execution_count":21,"outputs":[]}]}